\providecommand{\bbobECDFslegend}[1]{
Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for $51$ targets with target precision in $10^{[-8..2]}$ for all functions and subgroups in #1-D. The ``best 2009'' line corresponds to the best \aRT\ observed during BBOB 2009 for each selected target.
}
\providecommand{\bbobppfigslegend}[1]{
Average running time (\aRT\ in number of $f$-evaluations
                    as $\log_{10}$ value), divided by dimension for target function value $10^{-8}$
                    versus dimension. Slanted grid lines indicate quadratic scaling with the dimension. Different symbols correspond to different algorithms given in the legend of #1. Light symbols give the maximum number of function evaluations from the longest trial divided by dimension. Black stars indicate a statistically better result compared to all other algorithms with $p<0.01$ and Bonferroni correction number of dimensions (six).  
Legend: 
{\color{NavyBlue}$\circ$}: \algorithmA
, {\color{Magenta}$\diamondsuit$}: \algorithmB
}
\providecommand{\bbobpptablesmanylegend}[2]{%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the respective best \aRT\ measured during BBOB-2009 in
        #1.
        The \aRT\ and in braces, as dispersion measure, the half difference between 
        10 and 90\%-tile of bootstrapped run lengths appear for each algorithm and 
        %
        target, the corresponding best \aRT\
        in the first row. The different target \Df-values are shown in the top row.
        \#succ is the number of trials that reached the (final) target
        $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached. 
        Entries, succeeded by a star, are statistically significantly better (according to
        the rank-sum test) when compared to all other algorithms of the table, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k$ following the star is larger
        than 1, with Bonferroni correction of #2. A $\downarrow$ indicates the same tested against the best
        algorithm of BBOB-2009. Best results are printed in bold.
        }
\providecommand{\bbobpptablestwolegend}[1]{
%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the respective best \aRT\ measured during BBOB-2009 in
        dimensions 5 (left) and 20 (right).
        The \aRT\ and in braces, as dispersion measure, the half difference between 10
        and 90\%-tile of bootstrapped run lengths appear for each algorithm and 
        %
        target, the corresponding best \aRT\
        in the first row. The different target \Df-values are shown in the top row. 
        \#succ is the number of trials that reached the (final) target
        $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the last target was never reached. 
        1:\algorithmAshort\ is \algorithmA\ and 2:\algorithmBshort\ is \algorithmB.
        Bold entries are statistically significantly better compared to the other algorithm,
        with $p=0.05$ or $p=10^{-k}$ where $k\in\{2,3,4,\dots\}$ is the number
        following the $\star$ symbol, with Bonferroni correction of #1.A $\downarrow$ indicates the same tested against the best
        algorithm of BBOB-2009.
}
\providecommand{\bbobppscatterlegend}[1]{
Average running time (\aRT\ in $\log_{10}$ of number of function evaluations)
        of \algorithmB\ ($x$-axis) versus \algorithmA\ ($y$-axis) for $46$ target values
        $\Df \in [100, 10^{-8}]$ in each dimension on functions #1. Markers on the upper or right edge indicate that the respective target
        value was never reached. Markers represent dimension:
        2:{\color{cyan}+},
        3:{\color{green!45!black}$\triangledown$},
        5:{\color{blue}$\star$},
        10:$\circ$,
        20:{\color{red}$\Box$},
        40:{\color{magenta}$\Diamond$}. 
}
\providecommand{\bbobpprldistrlegendtwo}[1]{
%
        Empirical cumulative distributions (ECDF)
        of run lengths and speed-up ratios in 5-D (left) and 20-D (right).
        Left sub-columns: ECDF of
        the number of function evaluations divided by dimension $D$
        (FEvals/D) %
        to reach a target value $\fopt+\Df$ with $\Df=10^{k}$, where
        $k$ is given by the first value in the legend, for
        \algorithmA\ ({\color{Black}$\circ$}) and \algorithmB\ ({\color{Black}$\diamondsuit$})%
        . Light beige lines show the ECDF of FEvals for target value
        $\Df=10^{-8}$ of all algorithms benchmarked during
        BBOB-2009. Right sub-columns:
        ECDF of FEval ratios of \algorithmA\ divided by \algorithmB for target
        function values $10^k$ with $k$ given in the legend; all
        trial pairs for each function. Pairs where both trials failed are disregarded,
        pairs where one trial failed are visible in the limits being $>0$ or $<1$. The
        legend also indicates, after the colon, the number of functions that were
        solved in at least one trial (\algorithmA\ first).
}
\providecommand{\algorithmA}{A2 Carpediem}
\providecommand{\algorithmB}{A2 Zoubab}
\providecommand{\algname}{A2 Zoubab{}}
\providecommand{\algfolder}{A2_Zoubab/}
\providecommand{\bbobecdfcaptionallgroups}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes, measured in number
         of objective function evaluations, divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for all function groups and all dimensions. The aggregation over all 55 functions is shown in the last plot.
}
\providecommand{\bbobecdfcaptionsinglefcts}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes in number
         of objective function evaluations divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for functions $f_1$ to $f_{16}$ and all dimensions. 
}
\providecommand{\bbobpptablecaption}[1]{
%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the best \aRT\ measured during BBOB-2009. The \aRT\ 
        and in braces, as dispersion measure, the half difference between 90 and 
        10\%-tile of bootstrapped run lengths appear in the second row of each cell,  
        the best \aRT\
        %
        in the first. The different target \Df-values are shown in the top row. 
        \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached. 
        \textbf{Bold} entries are statistically significantly better (according to
        the rank-sum test) compared to the best algorithm in BBOB-2009, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k > 1$ is following the
        $\downarrow$ symbol, with Bonferroni correction by the number of
        functions.
        
}
\providecommand{\bbobppfigdimlegend}[1]{
%
        Scaling of runtime to reach $\fopt+10^{\#}$ with dimension;
        runtime is measured in number of $f$-evaluations and $\#$ is given in the legend;
        Lines: average runtime (\aRT);
        Cross (+): median runtime of successful runs to reach the most difficult
        target that was reached at least once (but not always);
        Cross ({\color{red}$\times$}): maximum number of
        $f$-evaluations in any trial. Notched
        boxes: interquartile range with median of simulated runs;
        % to reach $\fopt+10^{\#}$.
        %
        % Colors represent different target values. 
        All values are divided by dimension and 
        plotted as $\log_{10}$ values versus dimension. %
        %
        % Shown are $\Df = 10^{\{10, 1, 0.1, 0.01, 1e-3, 1e-5, 1e-8\}}$.  
        Numbers above \aRT-symbols (if appearing) indicate the number of trials
        reaching the respective target. The light thick line with
        diamonds indicates the respective best result from BBOB-2009 for
        $\Df=10^{-8}$. Horizontal lines mean linear scaling, slanted
        grid lines depict quadratic scaling.  
        
}
\providecommand{\bbobpprldistrlegend}[1]{
%
         Empirical cumulative distribution functions (ECDF), plotting the fraction of
         trials with an outcome not larger than the respective value on the $x$-axis.
         #1%
         Left subplots: ECDF of the number of function evaluations (FEvals) divided by search space dimension $D$,
         to fall below $\fopt+\Df$ with $\Df=10^{k}$, where $k$ is the first value in the legend.
         The thick red line represents the most difficult target value $\fopt+10^{-8}$. %
         Legends indicate for each target the number of functions that were solved in at
         least one trial within the displayed budget. %
         Right subplots: ECDF of the
         best achieved $\Df$
         for running times of $0.5D, 1.2D, 3D, 10D, 100D, 1000D,\dots$
         function evaluations
         (from right to left cycling cyan-magenta-black\dots) and final $\Df$-value (red),
         where \Df\ and \textsf{Df} denote the difference to the optimal function value. Light brown lines in the background show ECDFs for the most difficult target of all
         algorithms benchmarked during BBOB-2009.
}
\providecommand{\bbobloglossfigurecaption}[1]{
%
        \aRT\ loss ratios (see Figure~\ref{tab:aRTloss} for details).
        Each cross ({\color{blue}$+$}) represents a single function, the line
        is the geometric mean.
        
}
\providecommand{\bbobloglosstablecaption}[1]{
%
        \aRT\ loss ratio versus the budget in number of $f$-evaluations
        divided by dimension.
        For each given budget \FEvals, the target value \ftarget\ is computed
        as the best target $f$-value reached within the
        budget by the given algorithm.
        Shown is then the \aRT\ to reach \ftarget\ for the given algorithm
        or the budget, if the GECCO-BBOB-2009 best algorithm
        reached a better target within the budget,
        divided by the best \aRT\
        seen in GECCO-BBOB-2009 to reach \ftarget.
        Line: geometric mean. Box-Whisker error bar: 25-75\%-ile with median
        (box), 10-90\%-ile (caps), and minimum and maximum \aRT\ loss ratio
        (points). The vertical line gives the maximal number of function evaluations
        in a single trial in this function subset. See also
        Figure~\ref{fig:aRTlogloss} for results on each function subgroup.
        
}
\providecommand{\algname}{A2 Carpediem{}}
\providecommand{\algfolder}{A2_Carpediem/}
\providecommand{\bbobecdfcaptionallgroups}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes, measured in number
         of objective function evaluations, divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for all function groups and all dimensions. The aggregation over all 55 functions is shown in the last plot.
}
\providecommand{\bbobecdfcaptionsinglefcts}{
Empirical cumulative distribution of simulated (bootstrapped) runtimes in number
         of objective function evaluations divided by dimension (FEvals/DIM) for the $51$ targets $10^{[-8..2]}$ for functions $f_1$ to $f_{16}$ and all dimensions. 
}
\providecommand{\bbobpptablecaption}[1]{
%
        Average running time (\aRT\ in number of function 
        evaluations) divided by the best \aRT\ measured during BBOB-2009. The \aRT\ 
        and in braces, as dispersion measure, the half difference between 90 and 
        10\%-tile of bootstrapped run lengths appear in the second row of each cell,  
        the best \aRT\
        %
        in the first. The different target \Df-values are shown in the top row. 
        \#succ is the number of trials that reached the (final) target $\fopt + 10^{-8}$.
        %
        The median number of conducted function evaluations is additionally given in 
        \textit{italics}, if the target in the last column was never reached. 
        \textbf{Bold} entries are statistically significantly better (according to
        the rank-sum test) compared to the best algorithm in BBOB-2009, with
        $p = 0.05$ or $p = 10^{-k}$ when the number $k > 1$ is following the
        $\downarrow$ symbol, with Bonferroni correction by the number of
        functions.
        
}
\providecommand{\bbobppfigdimlegend}[1]{
%
        Scaling of runtime to reach $\fopt+10^{\#}$ with dimension;
        runtime is measured in number of $f$-evaluations and $\#$ is given in the legend;
        Lines: average runtime (\aRT);
        Cross (+): median runtime of successful runs to reach the most difficult
        target that was reached at least once (but not always);
        Cross ({\color{red}$\times$}): maximum number of
        $f$-evaluations in any trial. Notched
        boxes: interquartile range with median of simulated runs;
        % to reach $\fopt+10^{\#}$.
        %
        % Colors represent different target values. 
        All values are divided by dimension and 
        plotted as $\log_{10}$ values versus dimension. %
        %
        % Shown are $\Df = 10^{\{10, 1, 0.1, 0.01, 1e-3, 1e-5, 1e-8\}}$.  
        Numbers above \aRT-symbols (if appearing) indicate the number of trials
        reaching the respective target. The light thick line with
        diamonds indicates the respective best result from BBOB-2009 for
        $\Df=10^{-8}$. Horizontal lines mean linear scaling, slanted
        grid lines depict quadratic scaling.  
        
}
\providecommand{\bbobpprldistrlegend}[1]{
%
         Empirical cumulative distribution functions (ECDF), plotting the fraction of
         trials with an outcome not larger than the respective value on the $x$-axis.
         #1%
         Left subplots: ECDF of the number of function evaluations (FEvals) divided by search space dimension $D$,
         to fall below $\fopt+\Df$ with $\Df=10^{k}$, where $k$ is the first value in the legend.
         The thick red line represents the most difficult target value $\fopt+10^{-8}$. %
         Legends indicate for each target the number of functions that were solved in at
         least one trial within the displayed budget. %
         Right subplots: ECDF of the
         best achieved $\Df$
         for running times of $0.5D, 1.2D, 3D, 10D, 100D, 1000D,\dots$
         function evaluations
         (from right to left cycling cyan-magenta-black\dots) and final $\Df$-value (red),
         where \Df\ and \textsf{Df} denote the difference to the optimal function value. Light brown lines in the background show ECDFs for the most difficult target of all
         algorithms benchmarked during BBOB-2009.
}
\providecommand{\bbobloglossfigurecaption}[1]{
%
        \aRT\ loss ratios (see Figure~\ref{tab:aRTloss} for details).
        Each cross ({\color{blue}$+$}) represents a single function, the line
        is the geometric mean.
        
}
\providecommand{\bbobloglosstablecaption}[1]{
%
        \aRT\ loss ratio versus the budget in number of $f$-evaluations
        divided by dimension.
        For each given budget \FEvals, the target value \ftarget\ is computed
        as the best target $f$-value reached within the
        budget by the given algorithm.
        Shown is then the \aRT\ to reach \ftarget\ for the given algorithm
        or the budget, if the GECCO-BBOB-2009 best algorithm
        reached a better target within the budget,
        divided by the best \aRT\
        seen in GECCO-BBOB-2009 to reach \ftarget.
        Line: geometric mean. Box-Whisker error bar: 25-75\%-ile with median
        (box), 10-90\%-ile (caps), and minimum and maximum \aRT\ loss ratio
        (points). The vertical line gives the maximal number of function evaluations
        in a single trial in this function subset. See also
        Figure~\ref{fig:aRTlogloss} for results on each function subgroup.
        
}
\providecommand{\algorithmAshort}{A2\_}
\providecommand{\algorithmBshort}{A2\_}
